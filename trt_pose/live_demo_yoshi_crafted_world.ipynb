{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Referenced from https://github.com/NVIDIA-AI-IOT/trt_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the JSON file which describes the human pose task.  This is in COCO format, it is the category descriptor pulled from the annotations file.  We modify the COCO category slightly, to add a neck keypoint.  We will use this task description JSON to create a topology tensor, which is an intermediate data structure that describes the part linkages, as well as which channels in the part affinity field each linkage corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import trt_pose.coco\n",
    "\n",
    "with open('human_pose.json', 'r') as f:\n",
    "    human_pose = json.load(f)\n",
    "\n",
    "topology = trt_pose.coco.coco_category_to_topology(human_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load our model.  Each model takes at least two parameters, *cmap_channels* and *paf_channels* corresponding to the number of heatmap channels\n",
    "and part affinity field channels.  The number of part affinity field channels is 2x the number of links, because each link has a channel corresponding to the\n",
    "x and y direction of the vector field for each link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trt_pose.models\n",
    "\n",
    "num_parts = len(human_pose['keypoints'])\n",
    "num_links = len(human_pose['skeleton'])\n",
    "\n",
    "model = trt_pose.models.resnet18_baseline_att(num_parts, 2 * num_links).cuda().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the model weights.  You will need to download these according to the table in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "MODEL_WEIGHTS = 'resnet18_baseline_att_224x224_A_epoch_249.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_WEIGHTS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize with TensorRT using the python library *torch2trt* we'll also need to create some example data.  The dimensions\n",
    "of this data should match the dimensions that the network was trained with.  Since we're using the resnet18 variant that was trained on\n",
    "an input resolution of 224x224, we set the width and height to these dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "\n",
    "data = torch.zeros((1, 3, HEIGHT, WIDTH)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt) to optimize the model.  We'll enable fp16_mode to allow optimizations to use reduced half precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized model may be saved so that we do not need to perform optimization again, we can just load the model.  Please note that TensorRT has device specific optimizations, so you can only use an optimized model on similar platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch2trt\n",
    "\n",
    "model_trt = torch2trt.torch2trt(model, [data], fp16_mode=True, max_workspace_size=1<<25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZED_MODEL = 'resnet18_baseline_att_224x224_A_epoch_249_trt.pth'\n",
    "\n",
    "torch.save(model_trt.state_dict(), OPTIMIZED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then load the saved model using *torch2trt* as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load(OPTIMIZED_MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can benchmark the model in FPS with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.4670517618843\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "torch.cuda.current_stream().synchronize()\n",
    "for i in range(50):\n",
    "    y = model_trt(data)\n",
    "torch.cuda.current_stream().synchronize()\n",
    "t1 = time.time()\n",
    "\n",
    "print(50.0 / (t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that will preprocess the image, which is originally in BGR8 / HWC format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def preprocess(image):\n",
    "    global device\n",
    "    device = torch.device('cuda')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define two callable classes that will be used to parse the objects from the neural network, as well as draw the parsed objects on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trt_pose.draw_objects import DrawObjects\n",
    "from trt_pose.parse_objects import ParseObjects\n",
    "\n",
    "parse_objects = ParseObjects(topology)\n",
    "draw_objects = DrawObjects(topology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you're using NVIDIA Jetson, you can use the [jetcam](https://github.com/NVIDIA-AI-IOT/jetcam) package to create an easy to use camera that will produce images in BGR8/HWC format.\n",
    "\n",
    "If you're not on Jetson, you may need to adapt the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.usb_camera import USBCamera\n",
    "# from jetcam.csi_camera import CSICamera\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "camera = USBCamera(width=WIDTH, height=HEIGHT, capture_fps=30)\n",
    "# camera = CSICamera(width=WIDTH, height=HEIGHT, capture_fps=30)\n",
    "\n",
    "camera.running = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the joycontrol tcp server.\n",
    "\n",
    "Skip the following cell if the joycontrol tcp server is not running yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "loop = asyncio.get_event_loop()\n",
    "tcpReader, tcpWriter = await asyncio.open_connection('127.0.0.1', 8080, loop=loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handler for sending joycontrol command manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button_clicked(b):\n",
    "    global tcpWriter\n",
    "    tcpWriter.write(b.tooltip.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toggle button state\n",
    "def on_button_long_clicked(b):\n",
    "    global tcpWriter\n",
    "    if b.button_style == '':\n",
    "        tcpWriter.write(b.tooltip.encode())\n",
    "        b.button_style = 'success'\n",
    "    else:\n",
    "        tcpWriter.write(b.tooltip.upper().encode())\n",
    "        b.button_style = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipywidgets for user interactions.\n",
    "\n",
    "Check the \"Control with data\" checkbox for sending the game controls from processTrtData to the joycontrol tcp server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a widget which will be used to display the camera feed with visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681223be5b8b4248a4c1d5a5fc488584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84af5a498a484f5aaa742a892405c7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, description='Control with data', indent=False),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c2cf77bc2a4bb5862d66049a3dd0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Value', description='Data', layout=Layout(height='30px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3ee56ac356430f971061f7d763d6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(icon='arrow-up', style=ButtonStyle(), tooltip='u'), Button(icon='arrow-down', style=Butt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b13dfa5f1594114b74b64e86397c29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(icon='arrow-up', style=ButtonStyle(), tooltip='m'), Button(icon='arrow-down', style=Butt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "image_w = ipywidgets.Image(format='jpeg')\n",
    "display(image_w)\n",
    "\n",
    "controllerCheckBox_w = ipywidgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Control with data',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "display(ipywidgets.HBox([controllerCheckBox_w]))\n",
    "\n",
    "dataText_w = ipywidgets.Text(\"Value\", description=\"Data\", layout=ipywidgets.Layout(width='100%', height='30px'))\n",
    "display(dataText_w)\n",
    "\n",
    "upButton = ipywidgets.Button(tooltip='u',icon='arrow-up')\n",
    "upButton.on_click(on_button_clicked)\n",
    "downButton = ipywidgets.Button(tooltip='d',icon='arrow-down')\n",
    "downButton.on_click(on_button_clicked)\n",
    "leftButton = ipywidgets.Button(tooltip='l',icon='arrow-left')\n",
    "leftButton.on_click(on_button_clicked)\n",
    "rightButton = ipywidgets.Button(tooltip='r',icon='arrow-right')\n",
    "rightButton.on_click(on_button_clicked)\n",
    "aButton = ipywidgets.Button(description=\"A\", tooltip='a')\n",
    "aButton.on_click(on_button_clicked)\n",
    "bButton = ipywidgets.Button(description=\"B\", tooltip='b')\n",
    "bButton.on_click(on_button_clicked)\n",
    "xButton = ipywidgets.Button(description=\"X\", tooltip='x')\n",
    "xButton.on_click(on_button_clicked)\n",
    "yButton = ipywidgets.Button(description=\"Y\", tooltip='y')\n",
    "yButton.on_click(on_button_clicked)\n",
    "lButton = ipywidgets.Button(description=\"L\", tooltip='L')\n",
    "lButton.on_click(on_button_clicked)\n",
    "rButton = ipywidgets.Button(description=\"R\", tooltip='R')\n",
    "rButton.on_click(on_button_clicked)\n",
    "lrButton = ipywidgets.Button(description=\"L+R\", tooltip='2')\n",
    "lrButton.on_click(on_button_clicked)\n",
    "\n",
    "upButtonLong = ipywidgets.Button(tooltip='m',icon='arrow-up')\n",
    "upButtonLong.on_click(on_button_long_clicked)\n",
    "downButtonLong = ipywidgets.Button(tooltip='n',icon='arrow-down')\n",
    "downButtonLong.on_click(on_button_long_clicked)\n",
    "leftButtonLong = ipywidgets.Button(tooltip='o',icon='arrow-left')\n",
    "leftButtonLong.on_click(on_button_long_clicked)\n",
    "rightButtonLong = ipywidgets.Button(tooltip='p',icon='arrow-right')\n",
    "rightButtonLong.on_click(on_button_long_clicked)\n",
    "aButtonLong = ipywidgets.Button(description=\"a\", tooltip='e')\n",
    "aButtonLong.on_click(on_button_long_clicked)\n",
    "bButtonLong = ipywidgets.Button(description=\"b\", tooltip='f')\n",
    "bButtonLong.on_click(on_button_long_clicked)\n",
    "xButtonLong = ipywidgets.Button(description=\"x\", tooltip='g')\n",
    "xButtonLong.on_click(on_button_long_clicked)\n",
    "yButtonLong = ipywidgets.Button(description=\"y\", tooltip='h')\n",
    "yButtonLong.on_click(on_button_long_clicked)\n",
    "\n",
    "targetingModeButton = ipywidgets.Button(description=\"T\", tooltip='?')\n",
    "\n",
    "display(ipywidgets.HBox([upButton, downButton, leftButton, rightButton, aButton, bButton, xButton, yButton, lButton, rButton, lrButton]))\n",
    "display(ipywidgets.HBox([upButtonLong, downButtonLong, leftButtonLong, rightButtonLong, aButtonLong, bButtonLong, xButtonLong, yButtonLong, lButton, rButton, targetingModeButton]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging data in batch. For testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "logDataSize = 100\n",
    "logDataQueue = deque(maxlen=logDataSize)\n",
    "logDataCounter = 0\n",
    "\n",
    "def logData(d):\n",
    "    global logDataQueue\n",
    "    global logDataCounter\n",
    "    global dataText_w\n",
    "    logDataQueue.append(d)\n",
    "    logDataCounter = logDataCounter + 1\n",
    "    if logDataCounter == logDataSize:\n",
    "        logDataCounter = 0\n",
    "        dataText_w.value = str(logDataQueue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major functions for transforming the trt data into game actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#flatten the normalized_peaks from torch.Size([1, 18, 100, 2]) to numpy([1, 36 + 1])\n",
    "#18 peaks * 2 coordinates (y,x) + 1 timestamp\n",
    "def getFlattenPeaks(object_counts, objects, normalized_peaks, timestamp):\n",
    "    count = int(object_counts[0])\n",
    "    flattenPeaks = np.zeros((count,objects[0][0].shape[0]*2 + 1)) #i.e. (1,36 + 1)\n",
    "    for i in range(count):\n",
    "        obj = objects[0][i]\n",
    "        C = obj.shape[0] #18\n",
    "        flattenPeaks[i][C*2] = timestamp #adding timestamp to the end\n",
    "        for j in range(C):\n",
    "            k = int(obj[j]) #obj index, i.e. k=0 for the 1st obj detected\n",
    "            if k >= 0:\n",
    "                    peak = normalized_peaks[0][j][k]\n",
    "                    flattenPeaks[i][j*2] = peak[0]\n",
    "                    flattenPeaks[i][j*2+1] = peak[1]\n",
    "    return flattenPeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPose:\n",
    "    poseIndexNose = 0\n",
    "    poseIndexLeftEye = 1\n",
    "    poseIndexRightEye = 2\n",
    "    poseIndexLeftEar = 3\n",
    "    poseIndexRightEar = 4\n",
    "    poseIndexLeftShoulder = 5\n",
    "    poseIndexRightShoulder = 6\n",
    "    poseIndexLeftElbow = 7\n",
    "    poseIndexRightElbow = 8\n",
    "    poseIndexLeftWrist = 9\n",
    "    poseIndexRightWrist = 10\n",
    "    poseIndexLeftHip = 11\n",
    "    poseIndexRightHip = 12\n",
    "    poseIndexLeftKnee = 13\n",
    "    poseIndexRightKnee = 14\n",
    "    poseIndexLeftAnkle = 15\n",
    "    poseIndexRightAnkle = 16\n",
    "    poseIndexNeck = 17\n",
    "    poseIndexTimeStamp = 18\n",
    "    flattenIndexTimeStamp = poseIndexTimeStamp * 2\n",
    "\n",
    "    def xIndexOf(poseIndex):\n",
    "        return poseIndex * 2 + 1\n",
    "    \n",
    "    def yIndexOf(poseIndex):\n",
    "        return poseIndex * 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStatistic:\n",
    "    absMaxVal = 0\n",
    "    absMinVal = 0\n",
    "    absDVSpeed = 0\n",
    "    startingDVSign = 0\n",
    "    isDVInOneSign = 0\n",
    "    isAbsValIncreasing = 0\n",
    "    avgVal = 0\n",
    "    \n",
    "    def __init__(self, absMaxVal, absDVSpeed, startingDVSign, isDVInOneSign, isAbsValIncreasing, avgVal, absMinVal):\n",
    "        self.absMaxVal = absMaxVal\n",
    "        self.absMinVal = absMinVal\n",
    "        self.absDVSpeed = absDVSpeed\n",
    "        self.startingDVSign = startingDVSign\n",
    "        self.isDVInOneSign = isDVInOneSign\n",
    "        self.isAbsValIncreasing = isAbsValIncreasing\n",
    "        self.avgVal = avgVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStatisticOne:\n",
    "    maxVal = 0\n",
    "    minVal = 0\n",
    "    avgVal = 0\n",
    "    dVSpeed = 0\n",
    "    \n",
    "    def __init__(self, maxVal, minVal, avgVal, dVSpeed):\n",
    "        self.maxVal = maxVal\n",
    "        self.minVal = minVal\n",
    "        self.avgVal = avgVal\n",
    "        self.dVSpeed = dVSpeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyHeight = 0\n",
    "\n",
    "def getBodyHeight(flattenPeakQueue):\n",
    "    obj = flattenPeakQueue[0]\n",
    "    return obj[MyPose.yIndexOf(MyPose.poseIndexLeftAnkle)] - obj[MyPose.yIndexOf(MyPose.poseIndexNeck)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, flattenIndexA, flattenIndexB):\n",
    "    absMaxVal = 0\n",
    "    absMinVal = 0\n",
    "    lastVal = 0\n",
    "    lastT = 0\n",
    "    dVSum = 0\n",
    "    dTSum = 0\n",
    "    startingDVSign = 0\n",
    "    isDVInOneSign = True\n",
    "    lastAbsVal = 0\n",
    "    isAbsValIncreasing = True\n",
    "    valSum = 0\n",
    "    numOfElements = 0\n",
    "    for i, obj in enumerate(flattenPeakQueue):\n",
    "        aVal = obj[flattenIndexA]\n",
    "        bVal = obj[flattenIndexB]\n",
    "        t = obj[MyPose.flattenIndexTimeStamp]\n",
    "        val = bVal - aVal\n",
    "        valSum = valSum + val\n",
    "        numOfElements = numOfElements + 1\n",
    "        absVal = abs(val)\n",
    "        if i == 0:\n",
    "            absMaxVal = absVal\n",
    "            absMinVal = absVal\n",
    "        else:\n",
    "            if absVal > absMaxVal: absMaxVal = absVal\n",
    "            if absVal < absMinVal: absMinVal = absVal\n",
    "            dV = val - lastVal\n",
    "            dVSign = np.sign(dV)\n",
    "            if startingDVSign == 0:\n",
    "                startingDVSign = dVSign\n",
    "            else:\n",
    "                if dVSign != 0 and startingDVSign != dVSign: isDVInOneSign = False\n",
    "            if absVal < lastAbsVal: isAbsValIncreasing = False\n",
    "            dT = t - lastT\n",
    "            dVSum = dVSum + dV\n",
    "            dTSum = dTSum + dT\n",
    "        lastVal = val\n",
    "        lastT = t\n",
    "        lastAbsVal = absVal\n",
    "    if dTSum != 0:\n",
    "        dVSpeed = dVSum / dTSum\n",
    "    else:\n",
    "        dVSpeed = 0\n",
    "    avgVal = valSum / numOfElements\n",
    "    return MyStatistic(absMaxVal, abs(dVSpeed), startingDVSign, isDVInOneSign, isAbsValIncreasing, avgVal, absMinVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatisticsOfPeakInQueue(flattenPeakQueue, flattenIndex):\n",
    "    #global dataText_w\n",
    "    minVal = 0\n",
    "    maxVal = 0\n",
    "    valSum = 0\n",
    "    numOfElements = 0\n",
    "    dVSum = 0\n",
    "    dTSum = 0\n",
    "    lastVal = 0\n",
    "    lastT = 0\n",
    "    for i, obj in enumerate(flattenPeakQueue):\n",
    "        t = obj[MyPose.flattenIndexTimeStamp]\n",
    "        val = obj[flattenIndex]\n",
    "        valSum = valSum + val\n",
    "        numOfElements = numOfElements + 1\n",
    "        if i == 0:\n",
    "            minVal = val\n",
    "            maxVal = val\n",
    "        else:\n",
    "            if val > maxVal:\n",
    "                maxVal = val\n",
    "            if val < minVal:\n",
    "                minVal = val            \n",
    "            dV = val - lastVal\n",
    "            dT = t - lastT\n",
    "            dVSum = dVSum + dV\n",
    "            dTSum = dTSum + dT\n",
    "        lastVal = val\n",
    "        lastT = t\n",
    "    dVSpeed = dVSum / dTSum\n",
    "    avgVal = valSum / numOfElements\n",
    "    return MyStatisticOne(maxVal, minVal, avgVal, dVSpeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "isRunningSpeedScalingFactor=0.4\n",
    "\n",
    "def isRunningWithAnkle(flattenPeakQueue, hipIndex, ankleIndex):\n",
    "    global bodyHeight\n",
    "    global isRunningSpeedScalingFactor\n",
    "    s = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, hipIndex, ankleIndex)\n",
    "    return s.absMaxVal > bodyHeight*0.1 and s.absDVSpeed > bodyHeight*isRunningSpeedScalingFactor\n",
    "\n",
    "def getRunningDirWithKnee(flattenPeakQueue):\n",
    "    sR = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.xIndexOf(MyPose.poseIndexRightHip), MyPose.xIndexOf(MyPose.poseIndexRightKnee))\n",
    "    sL = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.xIndexOf(MyPose.poseIndexLeftHip), MyPose.xIndexOf(MyPose.poseIndexLeftKnee))\n",
    "    if sR.absMaxVal > sL.absMaxVal:\n",
    "        s = sR\n",
    "    else:\n",
    "        s = sL\n",
    "    if s.avgVal < 0:\n",
    "        return \"p\"\n",
    "    else:\n",
    "        return \"o\"\n",
    "    return \"?\"\n",
    "\n",
    "def isRunning(flattenPeakQueue):\n",
    "    return isRunningWithAnkle(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexRightHip), MyPose.yIndexOf(MyPose.poseIndexRightAnkle)) or isRunningWithAnkle(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexLeftHip), MyPose.yIndexOf(MyPose.poseIndexLeftAnkle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPunchingWithWrist(flattenPeakQueue, shoulderIndex, wristIndex):\n",
    "    global bodyHeight\n",
    "    s = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, shoulderIndex, wristIndex)\n",
    "    return s.absMaxVal > bodyHeight*0.25 and s.absDVSpeed > bodyHeight*0.1 and s.isDVInOneSign and s.isAbsValIncreasing\n",
    "\n",
    "def isPunching(flattenPeakQueue):\n",
    "    return isPunchingWithWrist(flattenPeakQueue, MyPose.xIndexOf(MyPose.poseIndexRightShoulder), MyPose.xIndexOf(MyPose.poseIndexRightWrist)) or isPunchingWithWrist(flattenPeakQueue, MyPose.xIndexOf(MyPose.poseIndexLeftShoulder), MyPose.xIndexOf(MyPose.poseIndexLeftWrist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isJumping(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    s = getStatisticsOfPeakInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexNeck))\n",
    "    maxDeltaVal = s.maxVal - s.minVal\n",
    "    return maxDeltaVal > bodyHeight * 0.1 and s.dVSpeed < -bodyHeight*0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "isExtendingBothWristsScalingFactor = 0.5\n",
    "\n",
    "#check if both wrist is extended\n",
    "#i.e. the deltaX of left and right wrist is over threshold\n",
    "def isExtendingBothWrists(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    global isExtendingBothWristsScalingFactor\n",
    "    s = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.xIndexOf(MyPose.poseIndexRightWrist), MyPose.xIndexOf(MyPose.poseIndexLeftWrist))\n",
    "    return s.absMaxVal > bodyHeight * isExtendingBothWristsScalingFactor\n",
    "\n",
    "def getFlyingDirWithWrists(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    sR = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexRightWrist), MyPose.yIndexOf(MyPose.poseIndexRightShoulder))\n",
    "    sL = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexLeftWrist), MyPose.yIndexOf(MyPose.poseIndexLeftShoulder))\n",
    "    if sR.absMaxVal < bodyHeight*0.1 and sL.absMaxVal < bodyHeight*0.1:\n",
    "        return \"0\"\n",
    "    elif sR.avgVal < -bodyHeight*0.1 and sL.avgVal > bodyHeight*0.1:\n",
    "        return \"p\"\n",
    "    elif sR.avgVal > bodyHeight*0.1 and sL.avgVal < -bodyHeight*0.1:\n",
    "        return \"o\"\n",
    "    return \"?\"\n",
    "\n",
    "def isFlying(flattenPeakQueue):\n",
    "    return isExtendingBothWrists(flattenPeakQueue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRightWristAboveShoulder(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    sR = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexRightWrist), MyPose.yIndexOf(MyPose.poseIndexRightShoulder))\n",
    "    return sR.avgVal > bodyHeight*0.2\n",
    "\n",
    "def isLeftWristAboveShoulder(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    sL = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexLeftWrist), MyPose.yIndexOf(MyPose.poseIndexLeftShoulder))\n",
    "    return sL.avgVal > bodyHeight*0.2\n",
    "\n",
    "def isBothWristsAboveShoulder(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    sR = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexRightWrist), MyPose.yIndexOf(MyPose.poseIndexRightShoulder))\n",
    "    sL = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexLeftWrist), MyPose.yIndexOf(MyPose.poseIndexLeftShoulder))\n",
    "    return sR.avgVal > bodyHeight*0.3 and sL.avgVal > bodyHeight*0.3\n",
    "\n",
    "def isBothWristsBelowKnee(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    sR = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexRightKnee), MyPose.yIndexOf(MyPose.poseIndexRightWrist))\n",
    "    sL = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexLeftKnee), MyPose.yIndexOf(MyPose.poseIndexLeftWrist))\n",
    "    return sR.avgVal > bodyHeight*0.1 and sL.avgVal > bodyHeight*0.1\n",
    "\n",
    "def isAnklesWideOpen(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    s = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.xIndexOf(MyPose.poseIndexLeftAnkle), MyPose.xIndexOf(MyPose.poseIndexRightAnkle))\n",
    "    return s.absMinVal > bodyHeight * 0.5\n",
    "\n",
    "def getUpDownFrom(flattenPeakQueue):\n",
    "    #if isBothWristsAboveShoulder(flattenPeakQueue):\n",
    "    if isRightWristAboveShoulder(flattenPeakQueue):\n",
    "        return \"u\"\n",
    "    #if isBothWristsBelowKnee(flattenPeakQueue):\n",
    "    if isAnklesWideOpen(flattenPeakQueue):\n",
    "        return \"d\"\n",
    "    return \"?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetingDirFromRightWrist(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    sX = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.xIndexOf(MyPose.poseIndexRightWrist), MyPose.xIndexOf(MyPose.poseIndexRightShoulder))\n",
    "    sY = getStatisticsBetweenTwoPeaksInQueue(flattenPeakQueue, MyPose.yIndexOf(MyPose.poseIndexRightWrist), MyPose.yIndexOf(MyPose.poseIndexRightShoulder))\n",
    "\n",
    "    if sY.absMaxVal > bodyHeight * 0.3 and sY.avgVal > 0:\n",
    "        return \"u\"\n",
    "    elif sY.absMaxVal > bodyHeight * 0.3 and sY.avgVal < 0:\n",
    "        return \"d\"\n",
    "    elif sX.absMaxVal > bodyHeight * 0.05 and sX.avgVal < 0:\n",
    "        return \"l\"\n",
    "    elif sX.absMaxVal > bodyHeight * 0.2 and sX.avgVal > 0:\n",
    "        return \"r\"\n",
    "    \n",
    "    return \"?\"\n",
    "\n",
    "def isTargeting(flattenPeakQueue):\n",
    "    return isLeftWristAboveShoulder(flattenPeakQueue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFlattennPeakQueueValid(flattenPeakQueue):\n",
    "    global bodyHeight\n",
    "    obj = flattenPeakQueue[0]\n",
    "    val0 = obj[MyPose.xIndexOf(MyPose.poseIndexNeck)]\n",
    "    val1 = obj[MyPose.xIndexOf(MyPose.poseIndexRightWrist)]\n",
    "    val2 = obj[MyPose.xIndexOf(MyPose.poseIndexLeftAnkle)]\n",
    "    return val0 != 0 and val1 != 0 and val2 != 0 and bodyHeight != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major game action logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortDirKeyList = [\"r\", \"l\", \"u\", \"d\"]\n",
    "longDirKeyList = [\"M\", \"N\", \"O\", \"P\", \"0\"]\n",
    "allDirKeyList = [\"r\", \"l\", \"u\", \"d\", \"M\", \"N\", \"O\", \"P\", \"0\"]\n",
    "longPressKeyList = [\"E\", \"F\", \"G\", \"H\", \"M\", \"N\", \"O\", \"P\", \"0\"]\n",
    "\n",
    "def isLongPressKey(controlKey):\n",
    "    global longPressKeyList\n",
    "    return controlKey.upper() in longPressKeyList\n",
    "\n",
    "def isLongDirKey(controkKey):\n",
    "    global longDirKeyList\n",
    "    return controlKey.upper() in longDirKeyList\n",
    "\n",
    "def isShortDirKey(controkKey):\n",
    "    global shortDirKeyList\n",
    "    return controkKey in shortDirKeyList\n",
    "\n",
    "def isShootingKey(controlKey):\n",
    "    return controlKey == \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rx.disposable.disposable.Disposable at 0x7f1eeb4828>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#direction control with rxpy\n",
    "import rx\n",
    "from rx import operators as op\n",
    "from rx.scheduler.eventloop import AsyncIOScheduler\n",
    "aio_scheduler = AsyncIOScheduler(loop=loop)\n",
    "\n",
    "dirControlObserver = 0\n",
    "def dirControlObservable(observer, scheduler):\n",
    "    global dirControlObserver\n",
    "    dirControlObserver = observer\n",
    "    \n",
    "rx.create(dirControlObservable).pipe(\n",
    "    op.filter(lambda val: val != \"?\")\n",
    "    #op.debounce(0.25)\n",
    "    #op.throttle_with_timeout(0.2)\n",
    ").subscribe(\n",
    "    #on_next = lambda val: publishControlKey(val), scheduler=aio_scheduler\n",
    "    on_next = lambda val: publishControlKey(val),\n",
    ")\n",
    "\n",
    "longControlObserver = 0\n",
    "def longControlObservable(observer, scheduler):\n",
    "    global longControlObserver\n",
    "    longControlObserver = observer\n",
    "\n",
    "rx.create(longControlObservable).pipe(\n",
    "    op.filter(lambda val: val != \"?\"),\n",
    "    op.distinct_until_changed()\n",
    ").subscribe(\n",
    "    on_next = lambda val: publishControlKey(val),\n",
    ")\n",
    "\n",
    "shootingControlObserver = 0\n",
    "def shootingControlObservable(observer, scheduler):\n",
    "    global shootingControlObserver\n",
    "    shootingControlObserver = observer\n",
    "\n",
    "dummyCnt = 0\n",
    "def onNextLog(val):\n",
    "    global dataText_w\n",
    "    global dummyCnt\n",
    "    dummyCnt = dummyCnt + 1\n",
    "    dataText_w.value = str(val) + ' ' + str(dummyCnt)\n",
    "\n",
    "rx.create(shootingControlObservable).pipe(\n",
    "    op.filter(lambda val: val != \"?\"),\n",
    "    #op.throttle_with_timeout(1.0, scheduler=aio_scheduler)\n",
    ").subscribe(\n",
    "    #on_next = lambda val: publishControlKey(val), scheduler=aio_scheduler\n",
    "    on_next = lambda val: publishControlKey(val),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "isTargetingMode = False\n",
    "isFlyingMode = False\n",
    "isRunningMode = False\n",
    "\n",
    "def getGameControlsFrom(flattenPeakQueue):\n",
    "    global isTargetingMode\n",
    "    global isFlyingMode\n",
    "    global isRunningMode\n",
    "    output = []\n",
    "    if not isFlattennPeakQueueValid(flattenPeakQueue):\n",
    "        return output\n",
    "    \n",
    "    if isTargetingMode:\n",
    "        if isTargeting(flattenPeakQueue):\n",
    "            lastElement = flattenPeakQueue[-1]\n",
    "            output.append(getTargetingDirFromRightWrist([lastElement]))\n",
    "        else:\n",
    "            isTargetingMode = False\n",
    "            output.append(\"x\")\n",
    "        return output\n",
    "\n",
    "    if isFlyingMode:\n",
    "        if isFlying(flattenPeakQueue):\n",
    "            output.append(getFlyingDirWithWrists(flattenPeakQueue))\n",
    "        else:\n",
    "            isFlyingMode = False\n",
    "            output.append(\"0\") #clear direction at the end of flying\n",
    "            output.append(\"E\")\n",
    "        return output\n",
    "\n",
    "    if isPunching(flattenPeakQueue):\n",
    "        output.append(\"b\")\n",
    "\n",
    "    if isRunningMode:\n",
    "        if isRunning(flattenPeakQueue):\n",
    "            output.append(getRunningDirWithKnee(flattenPeakQueue))\n",
    "        else:\n",
    "            isRunningMode = False\n",
    "            output.append(\"0\")\n",
    "        return output\n",
    "    \n",
    "    if isTargeting(flattenPeakQueue):\n",
    "        isTargetingMode = True\n",
    "        output.append(\"x\")\n",
    "        return output\n",
    "        \n",
    "    if isFlying(flattenPeakQueue):\n",
    "        isFlyingMode = True\n",
    "        output.append(\"e\")\n",
    "        return output\n",
    "\n",
    "    if isRunning(flattenPeakQueue):\n",
    "        isRunningMode = True\n",
    "        return output\n",
    "\n",
    "    #if isJumping(flattenPeakQueue):\n",
    "    #    output.append(\"a\")\n",
    "\n",
    "    output.append(getUpDownFrom(flattenPeakQueue))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastControlKey = \"a\"\n",
    "\n",
    "buttonKeyMapDict = {\n",
    "    \"a\": aButton,\n",
    "    \"b\": bButton,\n",
    "    \"x\": xButton,\n",
    "    \"y\": yButton,\n",
    "    \"u\": upButton,\n",
    "    \"d\": downButton,\n",
    "    \"l\": leftButton,\n",
    "    \"r\": rightButton,\n",
    "    \"L\": lButton,\n",
    "    \"R\": rButton,\n",
    "    \"E\": aButtonLong,\n",
    "    \"F\": bButtonLong,\n",
    "    \"G\": xButtonLong,\n",
    "    \"H\": yButtonLong,\n",
    "    \"M\": upButtonLong,\n",
    "    \"N\": downButtonLong,\n",
    "    \"O\": leftButtonLong,\n",
    "    \"P\": rightButtonLong,\n",
    "    \"T\": targetingModeButton\n",
    "}\n",
    "\n",
    "def displayAction(controlKey):\n",
    "    global lastControlKey\n",
    "    global buttonKeyMapDict\n",
    "    global isTargetingMode\n",
    "    if isLongPressKey(controlKey):\n",
    "        if controlKey == \"0\":\n",
    "            buttonKeyMapDict[\"M\"].button_style = ''\n",
    "            buttonKeyMapDict[\"N\"].button_style = ''\n",
    "            buttonKeyMapDict[\"O\"].button_style = ''\n",
    "            buttonKeyMapDict[\"P\"].button_style = ''\n",
    "        elif controlKey.isupper():\n",
    "            buttonKeyMapDict[controlKey].button_style = ''\n",
    "        else:\n",
    "            buttonKeyMapDict[controlKey.upper()].button_style = 'success'\n",
    "    elif isShortDirKey(controlKey):\n",
    "        buttonKeyMapDict[\"u\"].button_style = ''\n",
    "        buttonKeyMapDict[\"d\"].button_style = ''\n",
    "        buttonKeyMapDict[\"l\"].button_style = ''\n",
    "        buttonKeyMapDict[\"r\"].button_style = ''\n",
    "        buttonKeyMapDict[controlKey].button_style = 'success'\n",
    "    else:\n",
    "        buttonKeyMapDict[lastControlKey].button_style = ''\n",
    "        buttonKeyMapDict[controlKey].button_style = 'success'\n",
    "        lastControlKey = controlKey\n",
    "        if isTargetingMode:\n",
    "            buttonKeyMapDict[\"T\"].button_style = 'success'\n",
    "        else:\n",
    "            buttonKeyMapDict[\"T\"].button_style = ''            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publishControlKey(controlKey):\n",
    "    global tcpWriter\n",
    "    tcpWriter.write(controlKey.encode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "N = 5\n",
    "flattenPeakQueue = deque(maxlen=N)\n",
    "lastDirKeyAt = 0\n",
    "\n",
    "def processTrtData(object_counts, objects, normalized_peaks, timestamp):\n",
    "    global N\n",
    "    global flattenPeakQueue\n",
    "    #global dataText_w\n",
    "    global controllerCheckBox_w\n",
    "    global tcpWriter\n",
    "    global bodyHeight\n",
    "    global dirControlObserver\n",
    "    global longControlObserver\n",
    "    global shootingControlObserver\n",
    "    global lastDirKeyAt\n",
    "    flattenPeaks = getFlattenPeaks(object_counts, objects, normalized_peaks, timestamp)\n",
    "    if len(flattenPeaks) > 0:\n",
    "        flattenPeak = flattenPeaks[0]\n",
    "        flattenPeakQueue.append(flattenPeak)\n",
    "        if len(flattenPeakQueue) == N:\n",
    "            bodyHeight = getBodyHeight(flattenPeakQueue)\n",
    "            controlKeys = getGameControlsFrom(flattenPeakQueue)\n",
    "            if controllerCheckBox_w.value:\n",
    "                for k in controlKeys:\n",
    "                    if isLongPressKey(k):\n",
    "                        longControlObserver.on_next(k)\n",
    "                    elif isShortDirKey(k):\n",
    "                        t1 = time.time()\n",
    "                        dt = t1 - lastDirKeyAt\n",
    "                        if dt > 0.15:\n",
    "                            lastDirKeyAt = t1 \n",
    "                            dirControlObserver.on_next(k)\n",
    "                    elif isShootingKey(k):\n",
    "                        shootingControlObserver.on_next(k)\n",
    "                    elif k != \"?\":\n",
    "                        publishControlKey(k)                    \n",
    "            for k in controlKeys:\n",
    "                if k != \"?\":\n",
    "                    displayAction(k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For measuring the response time of the main processing loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSum = 0\n",
    "timeCount = 0\n",
    "timeCountN = 1000\n",
    "\n",
    "def recordTime(deltaTime):\n",
    "    global timeSum\n",
    "    global timeCount\n",
    "    global dataText_w\n",
    "    global timeCountN\n",
    "    timeSum = timeSum + deltaTime\n",
    "    timeCount = timeCount + 1\n",
    "    if timeCount >= timeCountN:\n",
    "        fps = timeCountN / timeSum\n",
    "        timeSum = 0\n",
    "        timeCount = 0\n",
    "        dataText_w.value = \"fps {}\".format(fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll define the main execution loop.  This will perform the following steps\n",
    "\n",
    "1.  Preprocess the camera image\n",
    "2.  Execute the neural network\n",
    "3.  Parse the objects from the neural network output\n",
    "4.  Draw the objects onto the camera image\n",
    "5.  Convert the image to JPEG format and stream to the display widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(change):\n",
    "    global saveImageCheckBox_w\n",
    "    global saveImageDelayCounter\n",
    "    t0 = time.time()\n",
    "    image = change['new']\n",
    "    data = preprocess(image)\n",
    "    cmap, paf = model_trt(data)\n",
    "    cmap, paf = cmap.detach().cpu(), paf.detach().cpu()\n",
    "    counts, objects, peaks = parse_objects(cmap, paf)#, cmap_threshold=0.15, link_threshold=0.15)\n",
    "    processTrtData(counts, objects, peaks, t0)\n",
    "    draw_objects(image, counts, objects, peaks)\n",
    "    image_w.value = bgr8_to_jpeg(image[:, ::-1, :])\n",
    "    t1 = time.time()\n",
    "    recordTime(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call the cell below it will execute the function once on the current camera frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the cell below to attach the execution function to the camera's internal value.  This will cause the execute function to be called whenever a new camera frame is received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the cell below to unattach the camera frame callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
